{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08a83c8f",
   "metadata": {},
   "source": [
    "# Feature 05: Historical Signal Performance Analysis\n",
    "**AI Chip Trading Signal System - Comprehensive Backtesting & Statistical Analysis**\n",
    "\n",
    "## üéØ Objective\n",
    "Validate our trading strategy's historical performance using:\n",
    "- **CSV-based data storage** for simple historical tracking\n",
    "- **Pandas vectorized backtesting** for efficient performance calculation\n",
    "- **scipy.stats** for statistical significance testing\n",
    "- **matplotlib/seaborn** for professional visualizations\n",
    "- **Market regime analysis** for understanding when signals work best\n",
    "\n",
    "## üìä Analysis Sections\n",
    "1. **Backend Environment Setup** - Load libraries and connect to running API\n",
    "2. **Historical Data Loading** - Import CSV data and real-time signals\n",
    "3. **Backtesting Engine** - Vectorized performance calculations\n",
    "4. **Statistical Analysis** - Significance testing and risk metrics\n",
    "5. **Visualization Dashboard** - Professional charts and regime analysis\n",
    "6. **Results Export** - Save findings for reporting and sharing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caef099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 1: Initialize Backend Environment\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add backend path for imports\n",
    "sys.path.append('../backend/src')\n",
    "\n",
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom backend modules\n",
    "from analysis.csv_data_manager import CSVDataManager\n",
    "from analysis.simple_backtester import SimpleBacktester\n",
    "from analysis.regime_analyzer import RegimeAnalyzer\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úÖ Libraries loaded successfully\")\n",
    "print(f\"üìä Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd5f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Backend API Connection\n",
    "BACKEND_URL = \"http://localhost:8000\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{BACKEND_URL}/\")\n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Backend API is running and responsive\")\n",
    "        api_status = response.json()\n",
    "        print(f\"   Status: {api_status.get('status', 'Unknown')}\")\n",
    "        print(f\"   Timestamp: {api_status.get('timestamp', 'Unknown')}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Backend API returned status code: {response.status_code}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Cannot connect to backend API: {e}\")\n",
    "    print(\"   Make sure backend is running on http://localhost:8000\")\n",
    "\n",
    "# Initialize Analysis Tools\n",
    "data_manager = CSVDataManager(data_dir=\"../backend/data/analysis_results\")\n",
    "backtester = SimpleBacktester(initial_capital=100000.0)\n",
    "regime_analyzer = RegimeAnalyzer()\n",
    "\n",
    "print(\"\\nüîß Analysis tools initialized:\")\n",
    "print(\"   - CSVDataManager: Simple file-based storage\")\n",
    "print(\"   - SimpleBacktester: Vectorized performance calculations\")\n",
    "print(\"   - RegimeAnalyzer: Market period classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da508b9",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Load Historical Data\n",
    "Import CSV data and fetch current signals from the API for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d037f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Sample Historical Data for Analysis\n",
    "print(\"üìÅ Creating sample historical data...\")\n",
    "sample_files = data_manager.create_sample_historical_data()\n",
    "print(f\"   ‚úÖ Signals file: {sample_files['signals']}\")\n",
    "print(f\"   ‚úÖ Price files: {len(sample_files['prices'])} symbols\")\n",
    "\n",
    "# Load Historical Signals\n",
    "historical_signals = data_manager.load_latest_signals()\n",
    "if historical_signals is not None:\n",
    "    print(f\"\\nüìä Loaded {len(historical_signals)} historical signals\")\n",
    "    print(f\"   Date range: {historical_signals['timestamp'].min()} to {historical_signals['timestamp'].max()}\")\n",
    "    print(f\"   Symbols: {historical_signals['symbol'].unique()}\")\n",
    "    print(f\"   Signal types: {historical_signals['signal_type'].value_counts().to_dict()}\")\n",
    "else:\n",
    "    print(\"‚ùå No historical signals data available\")\n",
    "    \n",
    "# Display sample data\n",
    "if historical_signals is not None:\n",
    "    print(\"\\nüìã Sample Historical Signals:\")\n",
    "    display(historical_signals.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a3809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Current Signals from Running Backend\n",
    "try:\n",
    "    print(\"üîÑ Fetching current signals from backend API...\")\n",
    "    \n",
    "    # Get current market data\n",
    "    market_response = requests.get(f\"{BACKEND_URL}/api/market-data\")\n",
    "    if market_response.status_code == 200:\n",
    "        current_data = market_response.json()\n",
    "        \n",
    "        print(\"‚úÖ Current Market Data Retrieved:\")\n",
    "        print(f\"   Bond Stress Level: {current_data['bond_stress']['signal_strength']}\")\n",
    "        print(f\"   Bond Confidence: {current_data['bond_stress']['confidence_score']}\")\n",
    "        print(f\"   Active Chip Signals: {len(current_data['chip_signals'])}\")\n",
    "        \n",
    "        # Convert current signals to DataFrame for analysis\n",
    "        if current_data['chip_signals']:\n",
    "            current_signals_df = pd.DataFrame(current_data['chip_signals'])\n",
    "            current_signals_df['timestamp'] = pd.to_datetime(current_signals_df['timestamp'])\n",
    "            \n",
    "            print(\"\\nüìà Current Active Signals:\")\n",
    "            display(current_signals_df[['symbol', 'signal_type', 'confidence_score', 'suggested_position_size']])\n",
    "        else:\n",
    "            print(\"   No active chip signals at this time\")\n",
    "            current_signals_df = pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"‚ùå Failed to fetch current data: {market_response.status_code}\")\n",
    "        current_signals_df = pd.DataFrame()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error fetching current signals: {e}\")\n",
    "    current_signals_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5ccbe9",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Perform Backtesting\n",
    "Implement vectorized calculations to evaluate historical signal performance using our simple backtesting engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Full Backtesting Analysis\n",
    "if historical_signals is not None and not historical_signals.empty:\n",
    "    print(\"üîÑ Running comprehensive backtesting analysis...\")\n",
    "    \n",
    "    # Run full backtest with train/test split\n",
    "    backtest_results = backtester.run_full_backtest(historical_signals, train_ratio=0.7)\n",
    "    \n",
    "    if 'error' not in backtest_results:\n",
    "        print(\"‚úÖ Backtesting completed successfully\\n\")\n",
    "        \n",
    "        # Display Training Period Results\n",
    "        train_perf = backtest_results['train_performance']\n",
    "        print(\"üìä TRAINING PERIOD PERFORMANCE:\")\n",
    "        print(f\"   Period: {backtest_results['train_period']['start']} to {backtest_results['train_period']['end']}\")\n",
    "        print(f\"   Total Trades: {train_perf['total_trades']}\")\n",
    "        print(f\"   Win Rate: {train_perf['win_rate']:.1%}\")\n",
    "        print(f\"   Total Return: {train_perf['total_return_pct']:.2f}%\")\n",
    "        print(f\"   Annualized Return: {train_perf['annualized_return_pct']:.2f}%\")\n",
    "        print(f\"   Sharpe Ratio: {train_perf['sharpe_ratio']:.2f}\")\n",
    "        print(f\"   Max Drawdown: {train_perf['max_drawdown_pct']:.2f}%\")\n",
    "        \n",
    "        # Display Test Period Results\n",
    "        test_perf = backtest_results['test_performance']\n",
    "        print(\"\\nüìä TEST PERIOD PERFORMANCE:\")\n",
    "        print(f\"   Period: {backtest_results['test_period']['start']} to {backtest_results['test_period']['end']}\")\n",
    "        print(f\"   Total Trades: {test_perf['total_trades']}\")\n",
    "        print(f\"   Win Rate: {test_perf['win_rate']:.1%}\")\n",
    "        print(f\"   Total Return: {test_perf['total_return_pct']:.2f}%\")\n",
    "        print(f\"   Annualized Return: {test_perf['annualized_return_pct']:.2f}%\")\n",
    "        print(f\"   Sharpe Ratio: {test_perf['sharpe_ratio']:.2f}\")\n",
    "        print(f\"   Max Drawdown: {test_perf['max_drawdown_pct']:.2f}%\")\n",
    "        \n",
    "        # Statistical Significance\n",
    "        sig_test = backtest_results['significance_test']\n",
    "        if 'error' not in sig_test:\n",
    "            print(\"\\nüìà STATISTICAL SIGNIFICANCE:\")\n",
    "            print(f\"   T-Statistic: {sig_test['t_statistic']:.3f}\")\n",
    "            print(f\"   P-Value: {sig_test['p_value']:.4f}\")\n",
    "            print(f\"   Significant at 95%: {'‚úÖ YES' if sig_test['significant_at_95'] else '‚ùå NO'}\")\n",
    "            print(f\"   Train Mean Return: {sig_test['train_mean_return']:.2%}\")\n",
    "            print(f\"   Test Mean Return: {sig_test['test_mean_return']:.2%}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Backtesting failed: {backtest_results['error']}\")\n",
    "        backtest_results = None\n",
    "else:\n",
    "    print(\"‚ùå No historical signals available for backtesting\")\n",
    "    backtest_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b268c00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Risk Metrics and Drawdown Analysis\n",
    "if backtest_results and 'error' not in backtest_results:\n",
    "    print(\"üîç Calculating Additional Risk Metrics...\")\n",
    "    \n",
    "    # Get portfolio curves for detailed analysis\n",
    "    train_portfolio = backtest_results['train_performance']['portfolio_values']\n",
    "    test_portfolio = backtest_results['test_performance']['portfolio_values']\n",
    "    \n",
    "    if train_portfolio and test_portfolio:\n",
    "        # Convert to DataFrames for analysis\n",
    "        train_df = pd.DataFrame(train_portfolio)\n",
    "        test_df = pd.DataFrame(test_portfolio)\n",
    "        \n",
    "        train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "        test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "        \n",
    "        # Calculate additional metrics\n",
    "        print(\"\\nüìä DETAILED RISK ANALYSIS:\")\n",
    "        \n",
    "        # Training period analysis\n",
    "        train_returns = train_df['value'].pct_change().dropna()\n",
    "        train_downside = train_returns[train_returns < 0].std()\n",
    "        train_sortino = (train_returns.mean() / train_downside) * np.sqrt(252) if train_downside > 0 else 0\n",
    "        \n",
    "        print(f\"   Training Sortino Ratio: {train_sortino:.2f}\")\n",
    "        print(f\"   Training Return Volatility: {train_returns.std() * np.sqrt(252):.2%}\")\n",
    "        print(f\"   Training Worst Month: {train_returns.min():.2%}\")\n",
    "        \n",
    "        # Test period analysis\n",
    "        test_returns = test_df['value'].pct_change().dropna()\n",
    "        test_downside = test_returns[test_returns < 0].std()\n",
    "        test_sortino = (test_returns.mean() / test_downside) * np.sqrt(252) if test_downside > 0 else 0\n",
    "        \n",
    "        print(f\"   Test Sortino Ratio: {test_sortino:.2f}\")\n",
    "        print(f\"   Test Return Volatility: {test_returns.std() * np.sqrt(252):.2%}\")\n",
    "        print(f\"   Test Worst Month: {test_returns.min():.2%}\")\n",
    "        \n",
    "        # Store for later visualization\n",
    "        portfolio_analysis = {\n",
    "            'train_df': train_df,\n",
    "            'test_df': test_df,\n",
    "            'train_returns': train_returns,\n",
    "            'test_returns': test_returns\n",
    "        }\n",
    "    else:\n",
    "        print(\"‚ùå Portfolio value data not available for detailed analysis\")\n",
    "        portfolio_analysis = None\n",
    "else:\n",
    "    portfolio_analysis = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eca3ffe",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Statistical Analysis\n",
    "Use scipy.stats for significance testing and calculate advanced risk metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d256bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Statistical Significance Testing\n",
    "if historical_signals is not None and not historical_signals.empty:\n",
    "    print(\"üî¨ Performing Statistical Significance Testing...\")\n",
    "    \n",
    "    # Prepare data for statistical analysis\n",
    "    clean_signals = backtester.prepare_signals_data(historical_signals)\n",
    "    returns_data = backtester.calculate_basic_returns(clean_signals)\n",
    "    \n",
    "    if not returns_data.empty:\n",
    "        # Basic return statistics\n",
    "        returns_pct = returns_data['return_pct'] / 100  # Convert to decimal\n",
    "        \n",
    "        print(\"\\nüìä RETURN DISTRIBUTION ANALYSIS:\")\n",
    "        print(f\"   Sample Size: {len(returns_pct)}\")\n",
    "        print(f\"   Mean Return: {returns_pct.mean():.2%}\")\n",
    "        print(f\"   Median Return: {returns_pct.median():.2%}\")\n",
    "        print(f\"   Standard Deviation: {returns_pct.std():.2%}\")\n",
    "        print(f\"   Skewness: {stats.skew(returns_pct):.3f}\")\n",
    "        print(f\"   Kurtosis: {stats.kurtosis(returns_pct):.3f}\")\n",
    "        \n",
    "        # Test for normality\n",
    "        shapiro_stat, shapiro_p = stats.shapiro(returns_pct[:5000] if len(returns_pct) > 5000 else returns_pct)\n",
    "        print(f\"\\nüß™ NORMALITY TESTS:\")\n",
    "        print(f\"   Shapiro-Wilk Statistic: {shapiro_stat:.4f}\")\n",
    "        print(f\"   Shapiro-Wilk P-Value: {shapiro_p:.4f}\")\n",
    "        print(f\"   Normal Distribution: {'‚ùå NO' if shapiro_p < 0.05 else '‚úÖ YES'} (p < 0.05)\")\n",
    "        \n",
    "        # Test if returns are significantly different from zero\n",
    "        t_stat, t_p = stats.ttest_1samp(returns_pct, 0)\n",
    "        print(f\"\\nüìà STRATEGY EFFECTIVENESS:\")\n",
    "        print(f\"   T-Statistic vs Zero: {t_stat:.3f}\")\n",
    "        print(f\"   P-Value: {t_p:.4f}\")\n",
    "        print(f\"   Significantly Profitable: {'‚úÖ YES' if t_p < 0.05 and t_stat > 0 else '‚ùå NO'}\")\n",
    "        \n",
    "        # Confidence intervals\n",
    "        confidence_95 = stats.t.interval(0.95, len(returns_pct)-1, \n",
    "                                        loc=returns_pct.mean(), \n",
    "                                        scale=stats.sem(returns_pct))\n",
    "        confidence_99 = stats.t.interval(0.99, len(returns_pct)-1,\n",
    "                                        loc=returns_pct.mean(),\n",
    "                                        scale=stats.sem(returns_pct))\n",
    "        \n",
    "        print(f\"\\nüéØ CONFIDENCE INTERVALS:\")\n",
    "        print(f\"   95% CI: [{confidence_95[0]:.2%}, {confidence_95[1]:.2%}]\")\n",
    "        print(f\"   99% CI: [{confidence_99[0]:.2%}, {confidence_99[1]:.2%}]\")\n",
    "        \n",
    "        # Store statistical results\n",
    "        statistical_results = {\n",
    "            'returns_data': returns_data,\n",
    "            'returns_pct': returns_pct,\n",
    "            'normality_test': {'statistic': shapiro_stat, 'p_value': shapiro_p},\n",
    "            'profitability_test': {'t_statistic': t_stat, 'p_value': t_p},\n",
    "            'confidence_intervals': {'95': confidence_95, '99': confidence_99}\n",
    "        }\n",
    "    else:\n",
    "        print(\"‚ùå No returns data available for statistical analysis\")\n",
    "        statistical_results = None\n",
    "else:\n",
    "    statistical_results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Type and Symbol Performance Analysis\n",
    "if statistical_results:\n",
    "    print(\"\\nüîç SIGNAL TYPE PERFORMANCE BREAKDOWN:\")\n",
    "    \n",
    "    returns_data = statistical_results['returns_data']\n",
    "    \n",
    "    # Performance by signal type\n",
    "    signal_performance = returns_data.groupby('signal_type').agg({\n",
    "        'return_pct': ['count', 'mean', 'std', 'median'],\n",
    "        'win': 'mean',\n",
    "        'profit_loss': 'sum'\n",
    "    }).round(3)\n",
    "    \n",
    "    print(\"üìä By Signal Type:\")\n",
    "    for signal_type in returns_data['signal_type'].unique():\n",
    "        subset = returns_data[returns_data['signal_type'] == signal_type]\n",
    "        print(f\"   {signal_type}:\")\n",
    "        print(f\"     Count: {len(subset)}\")\n",
    "        print(f\"     Avg Return: {subset['return_pct'].mean():.2f}%\")\n",
    "        print(f\"     Win Rate: {subset['win'].mean():.1%}\")\n",
    "        print(f\"     Total P&L: ${subset['profit_loss'].sum():,.0f}\")\n",
    "    \n",
    "    # Performance by symbol\n",
    "    print(\"\\nüìä By Symbol:\")\n",
    "    for symbol in returns_data['symbol'].unique():\n",
    "        subset = returns_data[returns_data['symbol'] == symbol]\n",
    "        print(f\"   {symbol}:\")\n",
    "        print(f\"     Count: {len(subset)}\")\n",
    "        print(f\"     Avg Return: {subset['return_pct'].mean():.2f}%\")\n",
    "        print(f\"     Win Rate: {subset['win'].mean():.1%}\")\n",
    "        print(f\"     Total P&L: ${subset['profit_loss'].sum():,.0f}\")\n",
    "    \n",
    "    # Statistical tests between signal types\n",
    "    print(\"\\nüß™ SIGNAL TYPE COMPARISON:\")\n",
    "    now_returns = returns_data[returns_data['signal_type'] == 'NOW']['return_pct'] / 100\n",
    "    soon_returns = returns_data[returns_data['signal_type'] == 'SOON']['return_pct'] / 100\n",
    "    \n",
    "    if len(now_returns) > 0 and len(soon_returns) > 0:\n",
    "        t_stat, p_val = stats.ttest_ind(now_returns, soon_returns)\n",
    "        print(f\"   NOW vs SOON T-Test:\")\n",
    "        print(f\"     T-Statistic: {t_stat:.3f}\")\n",
    "        print(f\"     P-Value: {p_val:.4f}\")\n",
    "        print(f\"     Significant Difference: {'‚úÖ YES' if p_val < 0.05 else '‚ùå NO'}\")\n",
    "        print(f\"     NOW Mean: {now_returns.mean():.2%}\")\n",
    "        print(f\"     SOON Mean: {soon_returns.mean():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9fd590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Market Regime Analysis\n",
    "if historical_signals is not None and statistical_results:\n",
    "    print(\"\\nüåç MARKET REGIME ANALYSIS:\")\n",
    "    \n",
    "    # Generate comprehensive regime report\n",
    "    regime_report = regime_analyzer.generate_regime_report(\n",
    "        historical_signals, statistical_results['returns_data']\n",
    "    )\n",
    "    \n",
    "    print(f\"   Analysis covers {regime_report['total_signals_analyzed']} signals\")\n",
    "    print(f\"   Regimes with data: {regime_report['regimes_with_data']}\")\n",
    "    \n",
    "    # Display regime performance\n",
    "    if regime_report['regime_performance']:\n",
    "        print(\"\\nüìä PERFORMANCE BY MARKET REGIME:\")\n",
    "        for regime, performance in regime_report['regime_performance'].items():\n",
    "            if regime != 'unknown':\n",
    "                print(f\"\\n   {regime.upper()} ({performance['regime_info'].get('description', '')})\")\n",
    "                print(f\"     Signals: {performance['total_signals']}\")\n",
    "                print(f\"     Win Rate: {performance['win_rate']:.1%}\")\n",
    "                print(f\"     Avg Return: {performance['avg_return']:.2f}%\")\n",
    "                print(f\"     Total P&L: ${performance['total_pnl']:,.0f}\")\n",
    "                print(f\"     Characteristics: {performance['regime_info'].get('characteristics', '')}\")\n",
    "    \n",
    "    # Current market assessment\n",
    "    current_regime = regime_report['current_market_assessment']\n",
    "    print(f\"\\nüéØ CURRENT MARKET REGIME:\")\n",
    "    print(f\"   Regime: {current_regime['current_regime'].upper()}\")\n",
    "    print(f\"   Description: {current_regime['regime_description']}\")\n",
    "    print(f\"   Days in Regime: {current_regime['days_in_regime']}\")\n",
    "    print(f\"   Characteristics: {current_regime['regime_characteristics']}\")\n",
    "    \n",
    "    # Store regime analysis for visualization\n",
    "    regime_analysis = regime_report\n",
    "else:\n",
    "    regime_analysis = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d323719a",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Generate Visualizations\n",
    "Create professional performance charts using matplotlib and seaborn for interactive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd47b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Performance Visualization\n",
    "if portfolio_analysis and backtest_results:\n",
    "    print(\"üìä Creating Portfolio Performance Visualizations...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('AI Chip Trading Signal - Historical Performance Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Portfolio Value Over Time\n",
    "    ax1 = axes[0, 0]\n",
    "    train_df = portfolio_analysis['train_df']\n",
    "    test_df = portfolio_analysis['test_df']\n",
    "    \n",
    "    ax1.plot(train_df['date'], train_df['value'], label='Training Period', linewidth=2, alpha=0.8)\n",
    "    ax1.plot(test_df['date'], test_df['value'], label='Test Period', linewidth=2, alpha=0.8)\n",
    "    ax1.axhline(y=100000, color='white', linestyle='--', alpha=0.5, label='Initial Capital')\n",
    "    ax1.set_title('Portfolio Value Over Time')\n",
    "    ax1.set_ylabel('Portfolio Value ($)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 2. Return Distribution\n",
    "    ax2 = axes[0, 1]\n",
    "    all_returns = np.concatenate([portfolio_analysis['train_returns'], portfolio_analysis['test_returns']])\n",
    "    ax2.hist(all_returns * 100, bins=30, alpha=0.7, edgecolor='white')\n",
    "    ax2.axvline(x=0, color='red', linestyle='--', alpha=0.8, label='Break Even')\n",
    "    ax2.set_title('Return Distribution')\n",
    "    ax2.set_xlabel('Return (%)')\n",
    "    ax2.set_ylabel('Frequency')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Rolling Sharpe Ratio\n",
    "    ax3 = axes[1, 0]\n",
    "    if len(portfolio_analysis['train_returns']) > 30:\n",
    "        rolling_sharpe_train = portfolio_analysis['train_returns'].rolling(30).mean() / portfolio_analysis['train_returns'].rolling(30).std() * np.sqrt(252)\n",
    "        ax3.plot(train_df['date'][30:], rolling_sharpe_train[30:], label='Training Sharpe (30-day)', linewidth=2)\n",
    "    \n",
    "    if len(portfolio_analysis['test_returns']) > 30:\n",
    "        rolling_sharpe_test = portfolio_analysis['test_returns'].rolling(30).mean() / portfolio_analysis['test_returns'].rolling(30).std() * np.sqrt(252)\n",
    "        ax3.plot(test_df['date'][30:], rolling_sharpe_test[30:], label='Test Sharpe (30-day)', linewidth=2)\n",
    "    \n",
    "    ax3.axhline(y=1.0, color='green', linestyle='--', alpha=0.5, label='Good Sharpe (1.0)')\n",
    "    ax3.set_title('Rolling 30-Day Sharpe Ratio')\n",
    "    ax3.set_ylabel('Sharpe Ratio')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Drawdown Analysis\n",
    "    ax4 = axes[1, 1]\n",
    "    train_cumret = (1 + portfolio_analysis['train_returns']).cumprod()\n",
    "    train_drawdown = (train_cumret - train_cumret.cummax()) / train_cumret.cummax()\n",
    "    \n",
    "    test_cumret = (1 + portfolio_analysis['test_returns']).cumprod()\n",
    "    test_drawdown = (test_cumret - test_cumret.cummax()) / test_cumret.cummax()\n",
    "    \n",
    "    ax4.fill_between(train_df['date'][1:], train_drawdown * 100, 0, alpha=0.6, label='Training Drawdown')\n",
    "    ax4.fill_between(test_df['date'][1:], test_drawdown * 100, 0, alpha=0.6, label='Test Drawdown')\n",
    "    ax4.set_title('Portfolio Drawdown Over Time')\n",
    "    ax4.set_ylabel('Drawdown (%)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Portfolio performance charts generated\")\n",
    "else:\n",
    "    print(\"‚ùå Portfolio analysis data not available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884e16a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Analysis and Regime Performance Charts\n",
    "if statistical_results and regime_analysis:\n",
    "    print(\"üìä Creating Signal Analysis and Regime Charts...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('Signal Performance Analysis by Type and Market Regime', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    returns_data = statistical_results['returns_data']\n",
    "    \n",
    "    # 1. Performance by Signal Type\n",
    "    ax1 = axes[0, 0]\n",
    "    signal_stats = returns_data.groupby('signal_type').agg({\n",
    "        'return_pct': 'mean',\n",
    "        'win': 'mean'\n",
    "    })\n",
    "    \n",
    "    x_pos = np.arange(len(signal_stats.index))\n",
    "    bars = ax1.bar(x_pos, signal_stats['return_pct'], alpha=0.8)\n",
    "    ax1.set_title('Average Return by Signal Type')\n",
    "    ax1.set_ylabel('Average Return (%)')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(signal_stats.index)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Win Rate by Signal Type\n",
    "    ax2 = axes[0, 1]\n",
    "    bars2 = ax2.bar(x_pos, signal_stats['win'] * 100, alpha=0.8, color='orange')\n",
    "    ax2.set_title('Win Rate by Signal Type')\n",
    "    ax2.set_ylabel('Win Rate (%)')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(signal_stats.index)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, bar in enumerate(bars2):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    # 3. Performance by Symbol\n",
    "    ax3 = axes[1, 0]\n",
    "    symbol_stats = returns_data.groupby('symbol')['return_pct'].mean().sort_values(ascending=True)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(symbol_stats)))\n",
    "    bars3 = ax3.barh(range(len(symbol_stats)), symbol_stats.values, color=colors, alpha=0.8)\n",
    "    ax3.set_title('Average Return by Symbol')\n",
    "    ax3.set_xlabel('Average Return (%)')\n",
    "    ax3.set_yticks(range(len(symbol_stats)))\n",
    "    ax3.set_yticklabels(symbol_stats.index)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Market Regime Performance\n",
    "    ax4 = axes[1, 1]\n",
    "    if regime_analysis['regime_performance']:\n",
    "        regime_returns = {}\n",
    "        for regime, perf in regime_analysis['regime_performance'].items():\n",
    "            if regime != 'unknown' and perf['total_signals'] > 0:\n",
    "                regime_returns[regime] = perf['avg_return']\n",
    "        \n",
    "        if regime_returns:\n",
    "            regimes = list(regime_returns.keys())\n",
    "            returns = list(regime_returns.values())\n",
    "            \n",
    "            bars4 = ax4.bar(regimes, returns, alpha=0.8, color='green')\n",
    "            ax4.set_title('Performance by Market Regime')\n",
    "            ax4.set_ylabel('Average Return (%)')\n",
    "            ax4.tick_params(axis='x', rotation=45)\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add value labels\n",
    "            for i, bar in enumerate(bars4):\n",
    "                height = bar.get_height()\n",
    "                ax4.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                        f'{height:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Signal analysis charts generated\")\n",
    "else:\n",
    "    print(\"‚ùå Signal analysis data not available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea705d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation and Statistical Analysis Heatmap\n",
    "if statistical_results:\n",
    "    print(\"üìä Creating Correlation and Statistical Analysis...\")\n",
    "    \n",
    "    returns_data = statistical_results['returns_data']\n",
    "    \n",
    "    # Create correlation matrix for numerical columns\n",
    "    numerical_cols = ['confidence_score', 'return_pct', 'profit_loss', 'position_size']\n",
    "    correlation_data = returns_data[numerical_cols]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    fig.suptitle('Correlation Analysis and Return Statistics', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Correlation Heatmap\n",
    "    ax1 = axes[0]\n",
    "    corr_matrix = correlation_data.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='RdYlBu_r', center=0, \n",
    "                square=True, ax=ax1, cbar_kws={\"shrink\": .8})\n",
    "    ax1.set_title('Signal Feature Correlations')\n",
    "    \n",
    "    # 2. Return Distribution by Confidence Score\n",
    "    ax2 = axes[1]\n",
    "    \n",
    "    # Bin confidence scores\n",
    "    returns_data['confidence_bin'] = pd.cut(returns_data['confidence_score'], \n",
    "                                          bins=[0, 5, 7, 10], \n",
    "                                          labels=['Low (0-5)', 'Medium (5-7)', 'High (7-10)'])\n",
    "    \n",
    "    # Box plot of returns by confidence\n",
    "    confidence_groups = []\n",
    "    confidence_labels = []\n",
    "    for label in returns_data['confidence_bin'].cat.categories:\n",
    "        group_data = returns_data[returns_data['confidence_bin'] == label]['return_pct']\n",
    "        if len(group_data) > 0:\n",
    "            confidence_groups.append(group_data)\n",
    "            confidence_labels.append(label)\n",
    "    \n",
    "    if confidence_groups:\n",
    "        bp = ax2.boxplot(confidence_groups, labels=confidence_labels, patch_artist=True)\n",
    "        \n",
    "        # Color the boxes\n",
    "        colors = ['lightcoral', 'lightblue', 'lightgreen']\n",
    "        for patch, color in zip(bp['boxes'], colors[:len(bp['boxes'])]):\n",
    "            patch.set_facecolor(color)\n",
    "            patch.set_alpha(0.7)\n",
    "        \n",
    "        ax2.set_title('Return Distribution by Confidence Level')\n",
    "        ax2.set_ylabel('Return (%)')\n",
    "        ax2.set_xlabel('Confidence Score Range')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print correlation insights\n",
    "    print(\"\\nüîç CORRELATION INSIGHTS:\")\n",
    "    high_corr = corr_matrix.abs() > 0.3\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i+1, len(corr_matrix.columns)):\n",
    "            if high_corr.iloc[i, j]:\n",
    "                print(f\"   {corr_matrix.columns[i]} <-> {corr_matrix.columns[j]}: {corr_matrix.iloc[i, j]:.3f}\")\n",
    "    \n",
    "    print(\"‚úÖ Correlation analysis completed\")\n",
    "else:\n",
    "    print(\"‚ùå Statistical results not available for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f6d15f",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Export Results\n",
    "Save analysis results as CSV files and export visualizations for reporting and sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be55f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export Comprehensive Analysis Results\n",
    "print(\"üíæ Exporting Analysis Results...\")\n",
    "\n",
    "# Create results summary\n",
    "analysis_summary = {\n",
    "    'analysis_timestamp': datetime.now().isoformat(),\n",
    "    'total_signals_analyzed': len(historical_signals) if historical_signals is not None else 0,\n",
    "    'backtest_completed': backtest_results is not None and 'error' not in backtest_results,\n",
    "    'statistical_analysis_completed': statistical_results is not None,\n",
    "    'regime_analysis_completed': regime_analysis is not None\n",
    "}\n",
    "\n",
    "if backtest_results and 'error' not in backtest_results:\n",
    "    # Export backtest results\n",
    "    print(\"üìä Exporting backtest results...\")\n",
    "    backtest_file = data_manager.save_backtest_results(backtest_results, \"feature_05_comprehensive\")\n",
    "    analysis_summary['backtest_file'] = backtest_file\n",
    "    \n",
    "    # Training performance summary\n",
    "    train_perf = backtest_results['train_performance']\n",
    "    analysis_summary.update({\n",
    "        'train_total_trades': train_perf['total_trades'],\n",
    "        'train_win_rate': train_perf['win_rate'],\n",
    "        'train_total_return_pct': train_perf['total_return_pct'],\n",
    "        'train_sharpe_ratio': train_perf['sharpe_ratio'],\n",
    "        'train_max_drawdown_pct': train_perf['max_drawdown_pct']\n",
    "    })\n",
    "    \n",
    "    # Test performance summary\n",
    "    test_perf = backtest_results['test_performance']\n",
    "    analysis_summary.update({\n",
    "        'test_total_trades': test_perf['total_trades'],\n",
    "        'test_win_rate': test_perf['win_rate'],\n",
    "        'test_total_return_pct': test_perf['total_return_pct'],\n",
    "        'test_sharpe_ratio': test_perf['sharpe_ratio'],\n",
    "        'test_max_drawdown_pct': test_perf['max_drawdown_pct']\n",
    "    })\n",
    "\n",
    "if statistical_results:\n",
    "    # Export statistical analysis results\n",
    "    print(\"üìà Exporting statistical analysis...\")\n",
    "    \n",
    "    # Save returns data with statistical metrics\n",
    "    returns_with_stats = statistical_results['returns_data'].copy()\n",
    "    returns_with_stats['analysis_timestamp'] = datetime.now()\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    stats_file = f\"../backend/data/analysis_results/statistical_analysis_{timestamp}.csv\"\n",
    "    returns_with_stats.to_csv(stats_file, index=False)\n",
    "    \n",
    "    analysis_summary.update({\n",
    "        'statistical_file': stats_file,\n",
    "        'mean_return_pct': statistical_results['returns_pct'].mean() * 100,\n",
    "        'return_volatility_pct': statistical_results['returns_pct'].std() * 100,\n",
    "        'normality_test_p_value': statistical_results['normality_test']['p_value'],\n",
    "        'profitability_test_p_value': statistical_results['profitability_test']['p_value']\n",
    "    })\n",
    "\n",
    "if regime_analysis:\n",
    "    # Export regime analysis\n",
    "    print(\"üåç Exporting regime analysis...\")\n",
    "    \n",
    "    regime_file = f\"../backend/data/analysis_results/regime_analysis_{timestamp}.json\"\n",
    "    with open(regime_file, 'w') as f:\n",
    "        # Convert datetime objects to strings for JSON serialization\n",
    "        import json\n",
    "        regime_json = json.dumps(regime_analysis, default=str, indent=2)\n",
    "        f.write(regime_json)\n",
    "    \n",
    "    analysis_summary['regime_file'] = regime_file\n",
    "    analysis_summary['current_regime'] = regime_analysis['current_market_assessment']['current_regime']\n",
    "\n",
    "# Save comprehensive summary\n",
    "summary_file = f\"../backend/data/analysis_results/feature_05_summary_{timestamp}.json\"\n",
    "with open(summary_file, 'w') as f:\n",
    "    json.dump(analysis_summary, f, indent=2, default=str)\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis results exported:\")\n",
    "print(f\"   üìä Summary: {summary_file}\")\n",
    "if 'backtest_file' in analysis_summary:\n",
    "    print(f\"   üîÑ Backtest: {analysis_summary['backtest_file']}\")\n",
    "if 'statistical_file' in analysis_summary:\n",
    "    print(f\"   üìà Statistics: {analysis_summary['statistical_file']}\")\n",
    "if 'regime_file' in analysis_summary:\n",
    "    print(f\"   üåç Regime Analysis: {analysis_summary['regime_file']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Analysis Summary and Next Steps\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéØ FEATURE 05: HISTORICAL ANALYSIS - EXECUTION COMPLETE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä ANALYSIS SUMMARY:\")\n",
    "if historical_signals is not None:\n",
    "    print(f\"   ‚úÖ Analyzed {len(historical_signals)} historical signals\")\n",
    "    print(f\"   ‚úÖ CSV data storage and management implemented\")\n",
    "    print(f\"   ‚úÖ Vectorized backtesting with train/test validation\")\n",
    "    print(f\"   ‚úÖ Statistical significance testing with scipy.stats\")\n",
    "    print(f\"   ‚úÖ Market regime analysis across major periods\")\n",
    "    print(f\"   ‚úÖ Professional matplotlib/seaborn visualizations\")\n",
    "    print(f\"   ‚úÖ Comprehensive results export to CSV/JSON\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  Sample data analysis completed (no historical signals available)\")\n",
    "\n",
    "print(\"\\nüéØ KEY FINDINGS:\")\n",
    "if backtest_results and 'error' not in backtest_results:\n",
    "    train_perf = backtest_results['train_performance']\n",
    "    test_perf = backtest_results['test_performance']\n",
    "    print(f\"   üìà Training Win Rate: {train_perf['win_rate']:.1%}\")\n",
    "    print(f\"   üìà Test Win Rate: {test_perf['win_rate']:.1%}\")\n",
    "    print(f\"   üí∞ Training Return: {train_perf['total_return_pct']:.2f}%\")\n",
    "    print(f\"   üí∞ Test Return: {test_perf['total_return_pct']:.2f}%\")\n",
    "    print(f\"   ‚öñÔ∏è Training Sharpe: {train_perf['sharpe_ratio']:.2f}\")\n",
    "    print(f\"   ‚öñÔ∏è Test Sharpe: {test_perf['sharpe_ratio']:.2f}\")\n",
    "\n",
    "if regime_analysis:\n",
    "    current_regime = regime_analysis['current_market_assessment']\n",
    "    print(f\"   üåç Current Market Regime: {current_regime['current_regime'].upper()}\")\n",
    "    print(f\"   üåç Regime Description: {current_regime['regime_description']}\")\n",
    "\n",
    "print(\"\\nüöÄ NEXT STEPS:\")\n",
    "print(\"   1. Review exported CSV files for detailed signal analysis\")\n",
    "print(\"   2. Integrate findings into real-time trading dashboard\")\n",
    "print(\"   3. Set up automated weekly performance reporting\")\n",
    "print(\"   4. Implement regime-aware position sizing adjustments\")\n",
    "print(\"   5. Create HTML reports for stakeholder sharing\")\n",
    "\n",
    "print(\"\\nüîß TECHNICAL ACHIEVEMENTS:\")\n",
    "print(\"   ‚úÖ Simple CSV-based data infrastructure\")\n",
    "print(\"   ‚úÖ Pandas vectorized backtesting engine\")\n",
    "print(\"   ‚úÖ Statistical significance validation\")\n",
    "print(\"   ‚úÖ Market regime classification system\")\n",
    "print(\"   ‚úÖ Professional visualization suite\")\n",
    "print(\"   ‚úÖ Automated results export pipeline\")\n",
    "\n",
    "print(f\"\\nüìÖ Analysis completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"\\nüéâ Feature 05: Historical Signal Performance Analysis - SUCCESSFUL EXECUTION!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
